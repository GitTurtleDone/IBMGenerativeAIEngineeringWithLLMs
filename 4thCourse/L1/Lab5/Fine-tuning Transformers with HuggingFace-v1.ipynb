{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03042563-c9f5-478c-aece-5a2872a23bdc",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c4112-2ae5-4d9f-a483-dc55829d9096",
   "metadata": {},
   "source": [
    "# **Fine-Tuning Transformers with PyTorch and Hugging Face**\n",
    "\n",
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b12f8-c91a-4534-a6d3-c8adfd4bfdc3",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project aims to introduce you to the process of loading and fine-tuning pretrained large language models (LLMs)\n",
    "\n",
    "You will learn how to implement the training loop of a model using pytorch to tune a model on task-specific data, as well as fine-tuning a model on task-specific data using the SFTTrainer module from Hugging Face. Finally, you will learn how to evaluate the performance of the fine-tuned models.\n",
    "\n",
    "By the end of this project, you will have a solid understanding of how to leverage pretrained LLMs and fine-tune them for your specific use cases, empowering you to create powerful and customized natural language processing solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb022b-88dc-42eb-854b-63dbf539498f",
   "metadata": {},
   "source": [
    "# **Table of Contents**\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "            <li><a href=\"#Importing-required-libraries\">Importing required libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Supervised-Fine-tuning-with-PyTorch)\">Supervised Fine-tuning with Pytorch</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Dataset-preparations\">Dataset preparations</a></li>\n",
    "            <li><a href=\"#Train-the-model\">Train the model</a></li>\n",
    "            <li><a href=\"#Evaluate\">Evaluate</a></li>\n",
    "            <li><a href=\"#Loading-the-saved-model\">Loading the saved model</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Exercise:-Training-a-conversational-model-using-SFTTrainer\">Exercise: Training a conversational model using SFTTrainer</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb877f-7b12-4737-a024-65b3add71d6b",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503bd5b-5019-4ad0-98cf-21aa4fccd7d5",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Load pretrained LLMs from Hugging Face and make inferences\n",
    "- Fine-tune a model on task-specific data using the SFTTrainer module from Hugging Face\n",
    "- Load a SFTTrainer pretrained model and make comparisons\n",
    "- Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e1b72-a640-4e2e-960b-f30954502bea",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4c850-8362-4f80-8e46-3f8ff908cc28",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37152eb3-399b-4e54-964c-0bc42dfa00ee",
   "metadata": {},
   "source": [
    "### Installing required libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!pip` in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6994db4f-2dbb-4d32-a987-6aefc469be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !pip install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 torch=2.1.0+cu118\n",
    "# - Update a specific package\n",
    "# !pip install pmdarima -U\n",
    "# - Update a package to specific version\n",
    "# !pip install --upgrade pmdarima==2.0.2\n",
    "# Note: If your environment doesn't support \"!pip install\", use \"!mamba install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b71957-49bb-433f-a338-4a42f16d8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting torch==2.2.2\n",
      "  Using cached torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch==2.2.2) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.3.1\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.3.1:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.3.1\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]32m1/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.19.3 torch-2.2.2\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: torchtext==0.17.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchtext==0.17.2) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchtext==0.17.2) (2.32.5)\n",
      "Requirement already satisfied: torch==2.2.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchtext==0.17.2) (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchtext==0.17.2) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchtext==0.17.2) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: portalocker==2.8.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (2.8.2)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: torchdata==0.7.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchdata==0.7.1) (2.5.0)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchdata==0.7.1) (2.32.5)\n",
      "Requirement already satisfied: torch>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchdata==0.7.1) (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata==0.7.1) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->torchdata==0.7.1) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=2->torchdata==0.7.1) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: pandas in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: matplotlib==3.9.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (3.9.0)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from matplotlib==3.9.0) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn==1.5.0) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn==1.5.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn==1.5.0) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.0) (1.17.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.18.1 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: transformers==4.42.1 in /home/giang/.local/lib/python3.12/site-packages (4.42.1)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers==4.42.1) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/giang/.local/lib/python3.12/site-packages (from transformers==4.42.1) (0.34.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers==4.42.1) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers==4.42.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/giang/.local/lib/python3.12/site-packages (from transformers==4.42.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/giang/.local/lib/python3.12/site-packages (from transformers==4.42.1) (2025.9.1)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers==4.42.1) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/giang/.local/lib/python3.12/site-packages (from transformers==4.42.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/giang/.local/lib/python3.12/site-packages (from transformers==4.42.1) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers==4.42.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers==4.42.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers==4.42.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers==4.42.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers==4.42.1) (2025.8.3)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: datasets in /home/giang/.local/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/giang/.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/giang/.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/giang/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/giang/.local/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/giang/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting torch==2.3.1\n",
      "  Using cached torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch==2.3.1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Using cached torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.2.2\u001b[0m \u001b[32m0/2\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.2.2:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.2.2m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]32m1/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.2 requires torch==2.2.2, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.20.5 torch-2.3.1\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: torchmetrics==1.4.0.post0 in /home/giang/.local/lib/python3.12/site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchmetrics==1.4.0.post0) (1.26.0)\n",
      "Requirement already satisfied: packaging>17.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchmetrics==1.4.0.post0) (25.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchmetrics==1.4.0.post0) (2.3.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/giang/.local/lib/python3.12/site-packages (from torchmetrics==1.4.0.post0) (0.15.2)\n",
      "Requirement already satisfied: setuptools in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.0.post0) (78.1.1)\n",
      "Requirement already satisfied: typing_extensions in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.0.post0) (4.15.0)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (3.19.1)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics==1.4.0.post0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics==1.4.0.post0) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->torchmetrics==1.4.0.post0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=1.10.0->torchmetrics==1.4.0.post0) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.2 requires torch==2.2.2, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: peft==0.11.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from peft==0.11.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from peft==0.11.1) (25.0)\n",
      "Requirement already satisfied: psutil in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from peft==0.11.1) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/giang/.local/lib/python3.12/site-packages (from peft==0.11.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from peft==0.11.1) (2.3.1)\n",
      "Requirement already satisfied: transformers in /home/giang/.local/lib/python3.12/site-packages (from peft==0.11.1) (4.42.1)\n",
      "Requirement already satisfied: tqdm in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from peft==0.11.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/giang/.local/lib/python3.12/site-packages (from peft==0.11.1) (0.31.0)\n",
      "Requirement already satisfied: safetensors in /home/giang/.local/lib/python3.12/site-packages (from peft==0.11.1) (0.6.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/giang/.local/lib/python3.12/site-packages (from peft==0.11.1) (0.34.4)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2025.3.0)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (1.1.9)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.11.1) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft==0.11.1) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/giang/.local/lib/python3.12/site-packages (from transformers->peft==0.11.1) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/giang/.local/lib/python3.12/site-packages (from transformers->peft==0.11.1) (0.19.1)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: evaluate==0.4.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/giang/.local/lib/python3.12/site-packages (from evaluate==0.4.2) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from evaluate==0.4.2) (1.26.4)\n",
      "Requirement already satisfied: dill in /home/giang/.local/lib/python3.12/site-packages (from evaluate==0.4.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from evaluate==0.4.2) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from evaluate==0.4.2) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from evaluate==0.4.2) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/giang/.local/lib/python3.12/site-packages (from evaluate==0.4.2) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/giang/.local/lib/python3.12/site-packages (from evaluate==0.4.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/giang/.local/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.2) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/giang/.local/lib/python3.12/site-packages (from evaluate==0.4.2) (0.34.4)\n",
      "Requirement already satisfied: packaging in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from evaluate==0.4.2) (25.0)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate==0.4.2) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate==0.4.2) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/giang/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate==0.4.2) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/giang/.local/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.2) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.2) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate==0.4.2) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate==0.4.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->evaluate==0.4.2) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate==0.4.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate==0.4.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->evaluate==0.4.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.2) (1.17.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: accelerate==0.31.0 in /home/giang/.local/lib/python3.12/site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate==0.31.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate==0.31.0) (25.0)\n",
      "Requirement already satisfied: psutil in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate==0.31.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/giang/.local/lib/python3.12/site-packages (from accelerate==0.31.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate==0.31.0) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/giang/.local/lib/python3.12/site-packages (from accelerate==0.31.0) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/giang/.local/lib/python3.12/site-packages (from accelerate==0.31.0) (0.6.2)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.31.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.31.0) (12.9.86)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.31.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.31.0) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.31.0) (1.1.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate==0.31.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.31.0) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate==0.31.0) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: torchvision==0.18.1 in /home/giang/.local/lib/python3.12/site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchvision==0.18.1) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchvision==0.18.1) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torchvision==0.18.1) (11.3.0)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision==0.18.1) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch==2.3.1->torchvision==0.18.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch==2.3.1->torchvision==0.18.1) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: trl==0.9.4 in /home/giang/.local/lib/python3.12/site-packages (0.9.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from trl==0.9.4) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/giang/.local/lib/python3.12/site-packages (from trl==0.9.4) (4.42.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from trl==0.9.4) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /home/giang/.local/lib/python3.12/site-packages (from trl==0.9.4) (0.31.0)\n",
      "Requirement already satisfied: datasets in /home/giang/.local/lib/python3.12/site-packages (from trl==0.9.4) (4.0.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/giang/.local/lib/python3.12/site-packages (from trl==0.9.4) (0.9.31)\n",
      "Requirement already satisfied: filelock in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (4.15.0)\n",
      "Requirement already satisfied: sympy in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/giang/.local/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.9.4) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.9.4) (12.9.86)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/giang/.local/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/giang/.local/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/giang/.local/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (2025.9.1)\n",
      "Requirement already satisfied: requests in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/giang/.local/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/giang/.local/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.9.4) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/giang/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.31.0->trl==0.9.4) (1.1.9)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/giang/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.9.4) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/giang/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.9.4) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/giang/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.9.4) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/giang/.local/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.9.4) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/giang/.local/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.9.4) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.9.4) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/giang/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.9.4) (0.1.2)\n",
      "Requirement already satisfied: psutil in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate->trl==0.9.4) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets->trl==0.9.4) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/giang/.local/lib/python3.12/site-packages (from datasets->trl==0.9.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets->trl==0.9.4) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /home/giang/.local/lib/python3.12/site-packages (from datasets->trl==0.9.4) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/giang/.local/lib/python3.12/site-packages (from datasets->trl==0.9.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/giang/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/giang/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.4) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.9.4) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.9.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.9.4) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->trl==0.9.4) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets->trl==0.9.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets->trl==0.9.4) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets->trl==0.9.4) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.9.4) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/giang/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=1.4.0->trl==0.9.4) (1.3.0)\n",
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: protobuf==3.20.* in /home/giang/.local/lib/python3.12/site-packages (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.2.2\n",
    "!pip install torchtext==0.17.2\n",
    "!pip install portalocker==2.8.2\n",
    "!pip install torchdata==0.7.1\n",
    "!pip install pandas\n",
    "!pip install matplotlib==3.9.0 scikit-learn==1.5.0\n",
    "!pip install numpy==1.26.0\n",
    "!pip install --user transformers==4.42.1\n",
    "!pip install --user datasets # 2.20.0\n",
    "# !pip install portalocker>=2.0.0\n",
    "# !pip install torch==2.3.1\n",
    "!pip install --user torchmetrics==1.4.0.post0\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install peft==0.11.1\n",
    "# !pip install evaluate==0.4.2\n",
    "# !pip install -q bitsandbytes==0.43.1\n",
    "!pip install --user accelerate==0.31.0\n",
    "!pip install --user torchvision==0.18.1\n",
    "\n",
    "\n",
    "!pip install --user trl==0.9.4\n",
    "!pip install --user protobuf==3.20.*\n",
    "# !pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36049975-0ce4-4d30-9b1b-f607165f0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d9cad-0c91-4f9f-ad65-ab11c1647920",
   "metadata": {},
   "source": [
    "### Importing required libraries\n",
    "\n",
    "_It is recommended that you import all required libraries in one place (here):_\n",
    "\n",
    "- Note: If you get an error after running the cell below, try restarting the Kernel, as some packages need a restart to be effective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user torchmetrics==1.4.0.post0\n",
    "# !pip install --user transformers==4.42.1\n",
    "# !pip install --user datasets # 2.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e368d57-33e5-42d5-82c0-fa78a4c9ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giang/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoConfig,AutoModelForCausalLM,AutoModelForSequenceClassification,BertConfig,BertForMaskedLM,TrainingArguments, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer,BertTokenizerFast,TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig,SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a411766-91c1-45be-aaa3-ec8f4c474aa2",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ba9ed-0c7e-4cf9-b2ce-b8d13f9de68f",
   "metadata": {},
   "source": [
    "# Supervised Fine-tuning with Pytorch\n",
    "\n",
    "Fine-tuning Transformers, specifically BERT (Bidirectional Encoder Representations from Transformers), refers to the process of training a pretrained BERT model on a specific downstream task. BERT is an encoder-only language model that has been pretrained on a large corpus of text to learn contextual representations of words.\n",
    "\n",
    "Fine-tuning BERT involves taking the pretrained model and further training it on a task-specific dataset, such as sentiment analysis or question answering. During fine-tuning, the parameters of the pretrained BERT model are updated and adapted to the specifics of the target task.\n",
    "\n",
    "This process is important because it allows you to leverage the knowledge and language understanding captured by BERT and apply it to different tasks. By fine-tuning BERT, you can benefit from its contextual understanding of language and transfer that knowledge to specific domain-specific or task-specific problems. Fine-tuning enables BERT to learn from a smaller labeled dataset and generalize well to unseen examples, making it a powerful tool for various natural language processing tasks. It helps to bridge the gap between pretraining on a large corpus and the specific requirements of downstream applications, ultimately improving the performance and effectiveness of models in various real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00432ef-3370-4af3-ad1e-8297b4d70c3b",
   "metadata": {},
   "source": [
    "## Dataset preparations\n",
    "\n",
    "The Yelp review dataset is a widely used dataset in natural language processing (NLP) and sentiment analysis research. It consists of user reviews and accompanying metadata from the Yelp platform, which is a popular online platform for reviewing and rating local businesses such as restaurants, hotels, and shops.\n",
    "\n",
    "The dataset includes 6,990,280 reviews written by Yelp users, covering a wide range of businesses and locations. Each review typically contains the text of the review itself alongwith the star rating given by the user (ranging from 1 to 5).\n",
    "\n",
    "Our aim in this lab, is to fine-tune a pretrained BERT model to predict the ratings from reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b302fd0-4986-4043-b46b-597f3120e814",
   "metadata": {},
   "source": [
    "Let's start by loading the yelp_review data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e78773-22b3-49fe-9900-ff55ac3ea2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 650000/650000 [00:03<00:00, 188990.97 examples/s]\n",
      "Generating test split: 100%|██████████| 50000/50000 [00:00<00:00, 302673.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbda62e-f0ed-4b01-bd3f-67426c9b1734",
   "metadata": {},
   "source": [
    "Let's check a sample record of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a26b14-7145-4465-80a9-0fdca7516d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf0306-05c4-49ed-86c4-e7f189dfde18",
   "metadata": {},
   "source": [
    "the label is the key of the class label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c12ea20-6082-49b2-a710-a42c1c11e2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b70ef4-8396-4c70-8a39-f6f67d4bf9bb",
   "metadata": {},
   "source": [
    "there is also the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42455364-e774-4f9b-85e4-1899d9531c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f6d9f-96fe-4b7d-92aa-4b10eee73128",
   "metadata": {},
   "source": [
    "You can select a portion of data to decrease the training time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c86ad9-f128-4a6b-b7f2-aef81fd0773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(1000)])\n",
    "dataset[\"test\"] = dataset[\"test\"].select([i for i in range(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999eada-2a91-4e79-9075-fcc2f18a3ffb",
   "metadata": {},
   "source": [
    "There are two data fields:\n",
    "\n",
    "- label: the label for the review\n",
    "- text: a string containing the body of the user review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95372d3c-b2cb-4c40-bdf4-6141bc4eb6b2",
   "metadata": {},
   "source": [
    "### Tokenizing data\n",
    "\n",
    "The next step is to load a BERT tokenizer to tokenize, pad and truncate reviews to handle variable-length sequences:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08866029-c9f4-4d9e-b1b0-0303460b1a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 1500.65 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 1749.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a tokenizer using the BERT base cased model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Define a function to tokenize examples\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the text using the tokenizer\n",
    "    # Apply padding to ensure all sequences have the same length\n",
    "    # Apply truncation to limit the maximum sequence length\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Apply the tokenize function to the dataset in batches\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6619c2-f898-4c8c-a290-3e1645401902",
   "metadata": {},
   "source": [
    "The keys in each element of tokenized_datasets are 'label', 'text', 'input_ids', 'token_type_ids', and 'attention_mask'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77138543-1f2c-4806-9c2d-16aefd20e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc4316-4ed5-4790-8d4f-f7e2cab83381",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, let's use the map method. You can speed up the map function by setting batched=True to process multiple elements of the dataset at once:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312db0cd-67f4-4529-8df9-23988bf977db",
   "metadata": {},
   "source": [
    "Since the model is built on the PyTorch framework, it is crucial to prepare the dataset in a format that PyTorch can readily process. Follow these steps to ensure compatibility:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6be34a02-88cb-4722-9872-06661be5f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the text column because the model does not accept raw text as an input\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# Rename the label column to labels because the model expects the argument to be named labels\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set the format of the dataset to return PyTorch tensors instead of lists\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f3fa0-9030-43ab-aada-7cf64835d342",
   "metadata": {},
   "source": [
    "the result is a set of tensors with the keys as: 'labels', 'input_ids', 'token_type_ids', 'attention_mask'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e568f2-3bc9-4000-9ac6-4bed5e013e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a896344-e245-4043-a6fa-d1e6c0b04d5f",
   "metadata": {},
   "source": [
    "### DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9715d5-a633-4516-ab58-f1bcc5b3d7f8",
   "metadata": {},
   "source": [
    "Next, create a DataLoader for train and test datasets so you can iterate over batches of data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b79d4ce-574a-49dd-bd33-eccc8ddce3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data loader\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=2)\n",
    "\n",
    "# Create an evaluation data loader\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493df6e6-b608-4852-8b85-c2f2278bed15",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974c057-4a0f-4f17-9d13-e5b5bb3c3085",
   "metadata": {},
   "source": [
    "You’re ready to start training your model, now!\n",
    "In this section, you will learn to create the training loop from scratch without the help of the Hugging Face trainer class.\n",
    "In the MLM task, you utilized the Hugging Face trainer module. Now, you will develop the trainer yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716814c-e61c-4377-a5fd-25393cb63e20",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d97d87-bab0-41d7-87d1-d863e849eb1b",
   "metadata": {},
   "source": [
    "Here, you'll load a pretrained classification model with 5 classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "620b3bae-7ad2-44b8-bd4a-6cdcde861888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a sequence classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4161dde-0bb4-45f9-934b-2f85b63d259a",
   "metadata": {},
   "source": [
    "### Optimizer and learning rate schedule\n",
    "\n",
    "Let's create an optimizer and learning rate scheduler to fine-tune the model. You can use the AdamW optimizer from PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ab8807-9615-431c-a378-a08971122e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Calculate the total number of training steps\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda current_step: (1 - current_step / num_training_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1622e8-ebd3-4cad-86a0-877584465ca6",
   "metadata": {},
   "source": [
    "Check if CUDA is available and, then set the device accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75dfa74d-2139-46ac-b591-84dfdfe82048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b888b1-7143-4018-81c6-879617e3aa13",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "You are ready to fine-tune the model. To keep track of training progress, let's use the \"tqdm\" library to add a progress bar over the number of training steps.\n",
    "The train_model function trains a model using a set of training data provided through a dataloader. It begins by setting up a progress bar to help monitor the training progress visually. The model is switched to training mode, which is necessary for certain model behaviors like dropout to work correctly during training. The function processes the data in batches for each epoch, which involves several steps for each batch: transferring the data to the correct device (like a GPU), running the data through the model to get outputs and calculate loss, updating the model's parameters using the calculated gradients, adjusting the learning rate, and clearing the old gradients. These steps are repeated for each batch of data, and the progress bar is updated accordingly to reflect the progress. Once all epochs are completed, the trained model is saved to be used later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d24b7d7a-36cc-4406-99a9-c1228d69e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,tr_dataloader):\n",
    "\n",
    "    # Create a progress bar to track the training progress\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    tr_losses=[]\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0 \n",
    "        # Iterate over the training data batches\n",
    "        for batch in tr_dataloader:\n",
    "            # Move the batch to the appropriate device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # Forward pass through the model\n",
    "            outputs = model(**batch)\n",
    "            # Compute the loss\n",
    "            loss = outputs.loss\n",
    "            # Backward pass (compute gradients)\n",
    "            loss.backward()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "            # Update the learning rate scheduler\n",
    "            lr_scheduler.step()\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "        tr_losses.append(total_loss/len(tr_dataloader))\n",
    "    #plot loss\n",
    "    plt.plot(tr_losses)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72774fa6-2666-498a-9889-d5a483f4eea0",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "The evaluate_model function works similarly to the train_model function but is used for evaluating the model's performance instead of training it. It uses a dataloader to process data in batches, setting the model to evaluation mode to ensure accuracy in measurements and disabling gradient calculations since it's not training. The function calculates predictions for each batch, updates an accuracy metric, and finally, prints the overall accuracy after processing all batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ae8bea1-49e5-4500-90f8-d24ad5b583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, evl_dataloader):\n",
    "    # Create an instance of the Accuracy metric for multiclass classification with 5 classes\n",
    "    metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation during evaluation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the evaluation data batches\n",
    "        for batch in evl_dataloader:\n",
    "            # Move the batch to the appropriate device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # Get the predicted class labels\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Accumulate the predictions and labels for the metric\n",
    "            metric(predictions, batch[\"labels\"])\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = metric.compute()\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy:\", accuracy.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3499b9d-374c-4db8-9c76-a5ce19772b98",
   "metadata": {},
   "source": [
    "You can now train the model. This process will take a long time, and it is highly recommended that you do this only if you have the required resources. Please uncomment the following code to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a829b61-26b2-4f19-9fc4-79ef857ace12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b895535e93bf40b0966d3b6bedb9e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_model(model=model,tr_dataloader=train_dataloader)\n",
    "\n",
    "# torch.save(model, 'my_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f6f48-774e-4569-802e-1d520600becc",
   "metadata": {},
   "source": [
    "![loss_gpt.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/HausLW2F_w30s1UK0zj7mQ/training-loss-BERT-Classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d56cd5-3e2f-4684-9123-6c419abd58ca",
   "metadata": {},
   "source": [
    "You are now ready to learn how to tune a more complex model that can generate conversations between a human and an assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e1fca-fd07-4978-9382-845fa41b1418",
   "metadata": {},
   "source": [
    "## Loading the saved model\n",
    "\n",
    "If you want to skip training and load the model that you trained for 10 epochs, go ahead and uncomment the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba3eea1-ada7-4317-b348-d4fd42e77a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "wget: /home/giang/miniconda3/envs/tf/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2025-09-08 13:02:36--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wFhKpkBMSgjmZKRSyayvsQ/bert-classification-model.pt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 433341834 (413M) [binary/octet-stream]\n",
      "Saving to: ‘bert-classification-model.pt.1’\n",
      "\n",
      "bert-classification 100%[===================>] 413.27M  3.41MB/s    in 66s     \n",
      "\n",
      "2025-09-08 13:03:43 (6.29 MB/s) - ‘bert-classification-model.pt.1’ saved [433341834/433341834]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wFhKpkBMSgjmZKRSyayvsQ/bert-classification-model.pt'\n",
    "model.load_state_dict(torch.load('bert-classification-model.pt',map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83627182-822d-4400-9ac9-f1003b41bc62",
   "metadata": {},
   "source": [
    "You can now evaluate the model. Please note that this process will take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e682506-6911-4345-9e66-9b19b9db7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26499998569488525\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b13d3-bc7d-4e68-959c-c0bf92fb0c63",
   "metadata": {},
   "source": [
    "You are now ready to learn to tune a more complex model that can generate conversations between a human and an assistant using SFTtrainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854700a-d27f-4f6f-98dc-27f5ddbfe159",
   "metadata": {},
   "source": [
    "# Exercise: Training a conversational model using SFTTrainer\n",
    "\n",
    "The SFTTrainer from the trl (Transformers Reinforcement Learning) library is a tool used for supervised fine-tuning of language models. It helps refine pre-trained models using specific datasets to enhance their performance on targeted tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048411d5-7550-435d-a83d-457df9b227ff",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Explore how fine-tuning a decoder transformer using a specific dataset affects the quality of the generated responses in a question-answering task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846359f0-cfd6-4168-b627-be6b01e6c2b4",
   "metadata": {},
   "source": [
    "Step 1- Load the train split of \"timdettmers/openassistant-guanaco\" dataset from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf2df3-8665-46f3-aeed-cbad92816203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "# dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "# dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text'])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2193b181-97c5-4743-b876-5f3f75c28027",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# load dataset\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "dataset[0]\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a997a66-7405-49fa-949a-54e9506724d4",
   "metadata": {},
   "source": [
    "Step 2- Load the pretrained causal model \"facebook/opt-350m\" along with its tokenizer from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "# device = \"cpu\"\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09306f-c6fa-4eb0-8f4e-fab5f99c94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3fedf6-e3c6-4ba8-9395-2a5b0c5336cc",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# load Hugging Face pretrained model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5a9f5-38c7-47db-a250-24f1cde3256a",
   "metadata": {},
   "source": [
    "Step 3- Create instruction and response templates based on the train dataset format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': SplitInfo(name='train', num_bytes=15808615, num_examples=9846, shard_lengths=None, dataset_name='openassistant-guanaco'), 'test': SplitInfo(name='test', num_bytes=839966, num_examples=518, shard_lengths=None, dataset_name='openassistant-guanaco')}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "builder = load_dataset_builder(\"timdettmers/openassistant-guanaco\")\n",
    "print(builder.info.splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec41cc9-95d7-4612-aa1a-62311b227b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "instruction_template = \"### Human:\"\n",
    "response_template = \"### Assistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337250b5-5a38-4678-aaa6-344555f8ed0f",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "instruction_template = \"### Human:\"\n",
    "response_template = \"### Assistant:\"\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc203c-54d7-4e00-ad86-3091d0a35b34",
   "metadata": {},
   "source": [
    "Step 4- Create a collator to curate data in the appropriate shape for training using **\"DataCollatorForCompletionOnlyLM\"**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f63a11-6c26-450e-a081-07c5705ae32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcbd95-bc2d-4c58-babf-3911f801f318",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8f6c6-da81-413e-a5d2-f0b80796fe04",
   "metadata": {},
   "source": [
    "Step 5- Create an SFTTrainer object and pass the model as well as the dataset and collator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2182dabc-ba07-4509-87cc-57d2ce47ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9846/9846 [00:04<00:00, 2461.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=1,\n",
    "    #learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=1,  # Reduce batch size\n",
    "    per_device_eval_batch_size=1,  # Reduce batch size\n",
    "    #gradient_accumulation_steps=4,  # Accumulate gradients\n",
    "    max_seq_length=10,\n",
    "    do_eval=True,\n",
    "    #no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b244ee-f80a-4b01-9fb6-c33b12460911",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    #learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    per_device_eval_batch_size=2,  # Reduce batch size\n",
    "    #gradient_accumulation_steps=4,  # Accumulate gradients\n",
    "    max_seq_length=1024,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=collator,\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c64c9-0fd8-4473-8560-5adacfacef8c",
   "metadata": {},
   "source": [
    "Step 6- Prompt the pretrained model with a specific question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81388015-3ab0-4443-bdc4-343f07f47a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "\n",
      "The term \"monopsony\" is used in the context of the \"mono\" (mono-economy) model. The term \"mono-economy\" is used in the context of the \"mono-economy\" model. The term \"mono-economy\" is used in the context of\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70, device=device)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who won US Open 2025?\n",
      "The US Open is the most prestigious tennis tournament in the world. It is the first Grand Slam tournament to be held in the United States since the coronavirus pandemic began.\n",
      "The tournament is held in New York City and is played in a single-elimination format. The top two players in each of the four major tournaments\n"
     ]
    }
   ],
   "source": [
    "print(pipe('''Who won US Open 2025''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdce10f-03c9-4ad1-9876-28870be9184f",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e33db3-c017-451e-b6ab-592391134023",
   "metadata": {},
   "source": [
    "Looks like the model is barely aware of what \"monopsony\" is in the context of economics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9df99-8c85-4f22-844d-8aa320d00a9b",
   "metadata": {},
   "source": [
    "Step 6A (Optional)- Train the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca82a097-04e2-47b7-b669-0b1cb027064a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Write your code here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:440\u001b[39m, in \u001b[36mSFTTrainer.train\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.neftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trainer_supports_neftune:\n\u001b[32m    438\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._trl_activate_neftune(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.neftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trainer_supports_neftune:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1932\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   1930\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   1931\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1932\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1937\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2268\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2265\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_begin(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.accumulate(model):\n\u001b[32m-> \u001b[39m\u001b[32m2268\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2271\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2272\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2273\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2274\u001b[39m ):\n\u001b[32m   2275\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2276\u001b[39m     tr_loss += tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3307\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs)\u001b[39m\n\u001b[32m   3304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3306\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3307\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3309\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3311\u001b[39m kwargs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3338\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs)\u001b[39m\n\u001b[32m   3336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3337\u001b[39m     labels = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3338\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3339\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3340\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:822\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:810\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/amp/autocast_mode.py:16\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:1118\u001b[39m, in \u001b[36mOPTForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1115\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m]).contiguous()\n\u001b[32m   1132\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:884\u001b[39m, in \u001b[36mOPTDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    874\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    875\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    876\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         use_cache,\n\u001b[32m    882\u001b[39m     )\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:525\u001b[39m, in \u001b[36mOPTDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    522\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.self_attn_layer_norm(hidden_states)\n\u001b[32m    524\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    533\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:206\u001b[39m, in \u001b[36mOPTAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttention mask should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39msrc_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_mask.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m         )\n\u001b[32m    205\u001b[39m     attn_weights = attn_weights.view(bsz, \u001b[38;5;28mself\u001b[39m.num_heads, tgt_len, src_len) + attention_mask\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     attn_weights = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     attn_weights = attn_weights.view(bsz * \u001b[38;5;28mself\u001b[39m.num_heads, tgt_len, src_len)\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# upcast to fp32 if the weights are in fp16. Please see https://github.com/huggingface/transformers/pull/17437\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "\n",
    "## Write your code here\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693e485-5593-4e6c-8084-36691181609e",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a04c6-1881-4ef5-b928-47744d1593f7",
   "metadata": {},
   "source": [
    "If you do not have enough resources to run the training, load the tuned model we provide here: \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt\":\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab0fb9-588a-440b-a806-38fa53b8657d",
   "metadata": {},
   "source": [
    "Step 6B- Load the tuned model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e33fd1-679d-4366-a68e-27e42f2f72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "wget: /home/giang/miniconda3/envs/tf/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2025-09-08 13:47:24--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1324934570 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘Assistant_model.pt’\n",
      "\n",
      "Assistant_model.pt  100%[===================>]   1.23G  7.78MB/s    in 2m 46s  \n",
      "\n",
      "2025-09-08 13:50:11 (7.62 MB/s) - ‘Assistant_model.pt’ saved [1324934570/1324934570]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt'\n",
    "model.load_state_dict(torch.load('Assistant_model.pt',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbd5a7-f6d7-4738-a86f-877aeaa0f13d",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt'\n",
    "model.load_state_dict(torch.load('Assistant_model.pt',map_location=torch.device('cpu')))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647c844-6803-452a-82b0-e90d3d4b1e76",
   "metadata": {},
   "source": [
    "Step 7- Check how the tuned model performs in answering the same specialized question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e62192-db53-4089-a278-48b603a6afac",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m torch.cuda.empty_cache()\n\u001b[32m      3\u001b[39m pipe = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model,tokenizer=tokenizer,max_new_tokens=\u001b[32m200\u001b[39m, device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)  \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'''\u001b[39;49m\u001b[33;43mCan you write a short introduction about the relevance of the term \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmonopsony\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\u001b[39;49m\u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:262\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(chats, **kwargs)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1254\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1247\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1248\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m         )\n\u001b[32m   1252\u001b[39m     )\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1261\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1260\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1262\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1161\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1159\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1160\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:349\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    346\u001b[39m         generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mmin_length\u001b[39m\u001b[33m\"\u001b[39m] += prefix_length\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m generated_sequence = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m out_b = generated_sequence.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:1914\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[39m\n\u001b[32m   1906\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   1907\u001b[39m         input_ids=input_ids,\n\u001b[32m   1908\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   1909\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   1910\u001b[39m         **model_kwargs,\n\u001b[32m   1911\u001b[39m     )\n\u001b[32m   1913\u001b[39m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   1926\u001b[39m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[32m   1927\u001b[39m     prepared_logits_warper = (\n\u001b[32m   1928\u001b[39m         \u001b[38;5;28mself\u001b[39m._get_logits_warper(generation_config, device=input_ids.device)\n\u001b[32m   1929\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m generation_config.do_sample\n\u001b[32m   1930\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1931\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:2651\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[39m\n\u001b[32m   2648\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2650\u001b[39m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2651\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[32m   2659\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:822\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/accelerate/utils/operations.py:810\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/amp/autocast_mode.py:16\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:1118\u001b[39m, in \u001b[36mOPTForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1115\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m]).contiguous()\n\u001b[32m   1132\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:884\u001b[39m, in \u001b[36mOPTDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    874\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    875\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    876\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         use_cache,\n\u001b[32m    882\u001b[39m     )\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:548\u001b[39m, in \u001b[36mOPTDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_layer_norm_before:\n\u001b[32m    546\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.final_layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.activation_fn(hidden_states)\n\u001b[32m    551\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.fc2(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "torch.cuda.empty_cache()\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=200, device = \"cuda\")  \n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/giang/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Mon Sep  8 13:59:00 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.104      Driver Version: 528.79       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M1200        On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8    N/A /  N/A |   4044MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     25685      C   /python3.12                     N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca0f86-85d0-4fc6-810f-c6c85695c24c",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e4575-1b54-4461-ae30-8896715e40d8",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e9630-74ff-4602-b909-704e17c9ae47",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48147d-0464-4507-b3b1-365184692577",
   "metadata": {},
   "source": [
    "[Fateme Akbari](https://author.skills.network/instructors/fateme_akbari) is a Ph.D. candidate in Information Systems at McMaster University with demonstrated research experience in Machine Learning and NLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b31f4-2630-47aa-a2e3-b171f3aa9818",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "prev_pub_hash": "a46cb4be48bad372e5cf1b1ca80ac3c279a2287fa4e1c50abe50c53d8edc661a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
